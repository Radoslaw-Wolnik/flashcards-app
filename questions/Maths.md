## **Analiza Matematyczna**

#### **1. ğŸ“˜ Podaj definicjÄ™ granicy ciÄ…gu liczbowego. SformuÅ‚uj treÅ›Ä‡ twierdzenia o trzech ciÄ…gach.**  
**Definicja granicy ciÄ…gu**:  
CiÄ…g liczbowy $(a_n)$ ma granicÄ™ $g \in \mathbb{R}$ (ozn. $\lim_{n \to \infty} a_n = g$), jeÅ›li:  
$$
\forall \varepsilon > 0  \ \exists N \in \mathbb{N}  \ \forall n > N : |a_n - g| < \varepsilon.
$$  
**Twierdzenie o trzech ciÄ…gach**:  
JeÅ›li dla ciÄ…gÃ³w $(a_n)$, $(b_n)$, $(c_n)$ zachodzi:  
1. $\exists N_0 \ \forall n > N_0 : a_n \leq b_n \leq c_n$,  
2. $\lim_{n \to \infty} a_n = \lim_{n \to \infty} c_n = g$,  
to $\lim_{n \to \infty} b_n = g$.

---

#### **2. ğŸ“˜ Podaj definicjÄ™ pochodnej funkcji jednej zmiennej. SformuÅ‚uj twierdzenie o wartoÅ›ci Å›redniej Lagrangeâ€™a.**  
**Definicja pochodnej**:  
PochodnÄ… funkcji $f$ w punkcie $x_0$ nazywamy granicÄ™:  
$$
f'(x_0) = \lim_{h \to 0} \frac{f(x_0 + h) - f(x_0)}{h}, \quad \text{o ile istnieje}.
$$  
**Twierdzenie Lagrangeâ€™a**:  
JeÅ›li funkcja $f$ jest:  
1. CiÄ…gÅ‚a w przedziale domkniÄ™tym $[a,b]$,  
2. RÃ³Å¼niczkowalna w przedziale otwartym $(a,b)$,  
to istnieje $c \in (a,b)$ takie, Å¼e:  
$$
f'(c) = \frac{f(b) - f(a)}{b - a}.
$$

---

#### **3. ğŸ’¡ OmÃ³w pojÄ™cie ekstremum lokalnego funkcji jednej zmiennej. Podaj warunek konieczny i wystarczajÄ…cy jego istnienia.**  
**Ekstremum lokalne**:  
- **Minimum lokalne**: $f(x_0) \leq f(x)$ dla $x$ w otoczeniu $x_0$.  
- **Maksimum lokalne**: $f(x_0) \geq f(x)$ dla $x$ w otoczeniu $x_0$.  

**Warunek konieczny (Fermata)**:  
JeÅ›li $f$ ma ekstremum lokalne w $x_0$ i jest rÃ³Å¼niczkowalna w $x_0$, to $f'(x_0) = 0$.  

**Warunki wystarczajÄ…ce**:  
1. **Pierwsza pochodna**:  
   - JeÅ›li $f'(x)$ zmienia znak z $-$ na $+$ w $x_0$, to $f$ ma minimum lokalne w $x_0$.  
   - JeÅ›li $f'(x)$ zmienia znak z $+$ na $-$ w $x_0$, to $f$ ma maksimum lokalne w $x_0$.  

2. **Druga pochodna**:  
   - JeÅ›li $f'(x_0) = 0$ i $f''(x_0) > 0$, to $f$ ma minimum lokalne w $x_0$.  
   - JeÅ›li $f'(x_0) = 0$ i $f''(x_0) < 0$, to $f$ ma maksimum lokalne w $x_0$.

---

#### **4. ğŸ“˜ Podaj warunek konieczny zbieÅ¼noÅ›ci szeregu liczbowego oraz dwa kryteria jego zbieÅ¼noÅ›ci.**  
**Warunek konieczny zbieÅ¼noÅ›ci**:  
JeÅ›li szereg $\sum_{n=1}^{\infty} a_n$ jest zbieÅ¼ny, to $\lim_{n \to \infty} a_n = 0$.  

**Kryteria zbieÅ¼noÅ›ci**:  
1. **Kryterium porÃ³wnawcze**:  
   JeÅ›li $0 \leq a_n \leq b_n$ i $\sum b_n$ zbieÅ¼ny, to $\sum a_n$ zbieÅ¼ny.  
2. **Kryterium dâ€™Alemberta (ilorazowe)**:  
   JeÅ›li $\lim_{n \to \infty} \left| \frac{a_{n+1}}{a_n} \right| = g$:  
   - $g < 1$ â†’ szereg zbieÅ¼ny,  
   - $g > 1$ â†’ szereg rozbieÅ¼ny.

---

#### **5. ğŸ’¡ WyjaÅ›nij pojÄ™cia: funkcja pierwotna, caÅ‚ka nieoznaczona. Podaj wzÃ³r na caÅ‚kowanie przez czÄ™Å›ci.**  
**Funkcja pierwotna**:  
Funkcja $F$ jest pierwotnÄ… funkcji $f$ w przedziale $I$, jeÅ›li $\forall x \in I: F'(x) = f(x)$.  

**CaÅ‚ka nieoznaczona**:  
ZbiÃ³r wszystkich funkcji pierwotnych $f$ oznaczamy $\int f(x)  dx = F(x) + C$, gdzie $C$ â€“ staÅ‚a.  

**CaÅ‚kowanie przez czÄ™Å›ci**:  
$$
\int u  dv = uv - \int v  du, \quad \text{gdzie } u = u(x),  dv = v'(x)  dx.
$$  
*PrzykÅ‚ad*:  
$\int x e^x  dx = x e^x - \int e^x  dx = x e^x - e^x + C$.

---

#### **6. ğŸ’¡ Podaj interpretacjÄ™ geometrycznÄ… caÅ‚ki oznaczonej. SformuÅ‚uj podstawowy wzÃ³r rachunku rÃ³Å¼niczkowego i caÅ‚kowego.**  
**Interpretacja geometryczna**:  
CaÅ‚ka oznaczona $\int_a^b f(x)  dx$ to pole obszaru ograniczonego:  
- osiÄ… $OX$,  
- prostymi $x = a$ i $x = b$,  
- wykresem funkcji $f(x)$ (dla $f(x) \geq 0$).  

**Podstawowe twierdzenie rachunku caÅ‚kowego (Newtona-Leibniza)**:  
JeÅ›li $f$ jest ciÄ…gÅ‚a w $[a,b]$ i $F$ jest jej funkcjÄ… pierwotnÄ…, to:  
$$
\int_a^b f(x)  dx = F(b) - F(a).
$$

---


## **Algebra Liniowa**

#### **1. ğŸ“˜ Podaj definicjÄ™ postaci algebraicznej oraz definicjÄ™ postaci trygonometrycznej liczby zespolonej. Podaj teÅ¼ wÅ‚asnoÅ›ci dziaÅ‚aÅ„ na liczbach zespolonych w postaci trygonometrycznej.**  
**PostaÄ‡ algebraiczna**:  
Liczba zespolona $ z = a + bi $, gdzie:  
- $ a, b \in \mathbb{R} $ â€“ czÄ™Å›Ä‡ rzeczywista (Re) i urojona (Im),  
- $ i $ â€“ jednostka urojona ($ i^2 = -1 $).  

**PostaÄ‡ trygonometryczna**:  
$ z = r(\cos \varphi + i \sin \varphi) $, gdzie:  
- $ r = |z| = \sqrt{a^2 + b^2} $ â€“ moduÅ‚,  
- $ \varphi = \arg z $ â€“ argument (kÄ…t z osiÄ… Re).  

**WÅ‚asnoÅ›ci dziaÅ‚aÅ„ w postaci trygonometrycznej**:  
- **MnoÅ¼enie**:  
  $$
  z_1 \cdot z_2 = r_1 r_2 \left[ \cos(\varphi_1 + \varphi_2) + i \sin(\varphi_1 + \varphi_2) \right]
  $$  
- **Dzielenie**:  
  $$
  \frac{z_1}{z_2} = \frac{r_1}{r_2} \left[ \cos(\varphi_1 - \varphi_2) + i \sin(\varphi_1 - \varphi_2) \right]
  $$  
- **PotÄ™gowanie (wzÃ³r de Moivreâ€™a)**:  
  $$
  z^n = r^n \left[ \cos(n\varphi) + i \sin(n\varphi) \right]
  $$  
- **Pierwiastkowanie**:  
  $$
  \sqrt[n]{z} = \sqrt[n]{r} \left[ \cos\left(\frac{\varphi + 2k\pi}{n}\right) + i \sin\left(\frac{\varphi + 2k\pi}{n}\right) \right], \quad k=0,1,\dots,n-1.
  $$

---

#### **2. ğŸ“˜ Podaj definicje i wÅ‚asnoÅ›ci podstawowych dziaÅ‚aÅ„ na macierzach.**  
**Definicje dziaÅ‚aÅ„**:  
- **Dodawanie**: $ [A + B]_{ij} = a_{ij} + b_{ij} $ (macierze tych samych wymiarÃ³w).  
- **MnoÅ¼enie przez skalar**: $ [cA]_{ij} = c \cdot a_{ij} $.  
- **MnoÅ¼enie macierzy**: $ [A \cdot B]_{ij} = \sum_{k} a_{ik} b_{kj} $ (liczba kolumn $A$ = liczba wierszy $B$).  
- **Transpozycja**: $ [A^T]_{ij} = a_{ji} $.  

**WÅ‚asnoÅ›ci**:  
- **Dodawanie**: przemienne ($A+B=B+A$), Å‚Ä…czne ($A+(B+C)=(A+B)+C$).  
- **MnoÅ¼enie macierzy**: Å‚Ä…czne ($A(BC)=(AB)C$), **nie** przemienne ($AB \neq BA$).  
- **RozdzielnoÅ›Ä‡**: $A(B+C) = AB + AC$.  
- **Transpozycja**: $(AB)^T = B^T A^T$, $(A^T)^T = A$.

---

#### **3. ğŸ’¡ Podaj definicjÄ™ i wÅ‚asnoÅ›ci macierzy odwrotnej oraz omÃ³w metody wyznaczania macierzy odwrotnej.**  
**Definicja**:  
Macierz $ A^{-1} $ jest odwrotna do $ A $ (kwadratowej), jeÅ›li:  
$$
A \cdot A^{-1} = A^{-1} \cdot A = I \quad (\text{macierz jednostkowa}).
$$  
**WÅ‚asnoÅ›ci**:  
- $(A^{-1})^{-1} = A$,  
- $(AB)^{-1} = B^{-1} A^{-1}$,  
- $(A^T)^{-1} = (A^{-1})^T$.  

**Metody wyznaczania**:  
1. **WzÃ³r z dopeÅ‚nieÅ„ algebraicznych**:  
   $$
   A^{-1} = \frac{1}{\det A} \cdot (\text{macierz dopeÅ‚nieÅ„})^T.
   $$  
2. **Metoda Gaussa-Jordana**:  
   - Tworzymy macierz blokowÄ… $[A | I]$,  
   - Redukujemy $A$ do postaci jednostkowej operacjami wierszowymi,  
   - Po redukcji blok prawy to $A^{-1}$.  
3. **Warunek istnienia**: $\det A \neq 0$ (macierz nieosobliwa).

---

#### **4. ğŸ“˜ Przedstaw podstawowe wÅ‚asnoÅ›ci i metody obliczania wyznacznika macierzy kwadratowej.**  
**WÅ‚asnoÅ›ci wyznacznika ($\det A$)**:  
- $\det(AB) = \det A \cdot \det B$,  
- $\det(A^T) = \det A$,  
- Zamiana wierszy/kolumn zmienia znak $\det$,  
- $\det(cA) = c^n \det A$ (dla macierzy $n \times n$).  

**Metody obliczania**:  
- **RozwiniÄ™cie Laplaceâ€™a** (wzglÄ™dem $i$-tego wiersza):  
  $$
  \det A = \sum_{j=1}^n (-1)^{i+j} a_{ij} \cdot M_{ij},
  $$  
  gdzie $M_{ij}$ â€“ minor (wyznacznik podmacierzy bez $i$-tego wiersza i $j$-tej kolumny).  
- **Metoda Gaussa**:  
  - Sprowadzamy macierz do postaci trÃ³jkÄ…tnej operacjami wierszowymi (bez skalowania!),  
  - $\det A$ = iloczyn elementÃ³w na przekÄ…tnej.  

---

#### **5. ğŸ’¡ OmÃ³w rÃ³Å¼ne metody rozwiÄ…zywania ukÅ‚adÃ³w rÃ³wnaÅ„ liniowych.**  
**UkÅ‚ad $n$ rÃ³wnaÅ„ z $n$ niewiadomymi**: $ A\mathbf{x} = \mathbf{b} $.  
1. **Metoda Cramera** (tylko gdy $\det A \neq 0$):  
   $$
   x_k = \frac{\det A_k}{\det A},
   $$  
   gdzie $A_k$ â€“ macierz $A$ z $k$-tÄ… kolumnÄ… zastÄ…pionÄ… wektorem $\mathbf{b}$.  
2. **Metoda macierzy odwrotnej** (tylko gdy $\det A \neq 0$):  
   $$
   \mathbf{x} = A^{-1} \mathbf{b}.
   $$  
3. **Metoda eliminacji Gaussa**:  
   - Tworzymy macierz rozszerzonÄ… $[A | \mathbf{b}]$,  
   - Sprowadzamy do postaci schodkowej (gÃ³rnotrÃ³jkÄ…tnej),  
   - RozwiÄ…zujemy od ostatniego rÃ³wnania w gÃ³rÄ™.  
4. **Metoda Gaussa-Jordana**:  
   - Redukujemy macierz rozszerzonÄ… do postaci jednostkowej,  
   - Wektor rozwiÄ…zaÅ„ w ostatniej kolumnie.

---

#### **6. ğŸ’¡ OmÃ³w najwaÅ¼niejsze podprzestrzenie wektorowe zwiÄ…zane z macierzÄ…, sposoby wyznaczania tych podprzestrzeni, ich bazy i wymiary.**  
**Kluczowe podprzestrzenie** (dla macierzy $A_{m \times n}$):  
1. **PrzestrzeÅ„ kolumnowa (obraz)**:  
   - $\text{Col}(A) = \{ A\mathbf{x} \mid \mathbf{x} \in \mathbb{R}^n \}$,  
   - **Baza**: kolumny liniowo niezaleÅ¼ne z $A$ (po redukcji do postaci schodkowej),  
   - **Wymiar**: $\text{rk}(A)$ (rzÄ…d macierzy).  
2. **PrzestrzeÅ„ wierszowa**:  
   - $\text{Row}(A) = \text{Col}(A^T)$,  
   - **Baza**: niezerowe wiersze z zredukowanej postaci schodkowej,  
   - **Wymiar**: $\text{rk}(A)$.  
3. **JÄ…dro (jÄ…dro)**:  
   - $\text{Ker}(A) = \{ \mathbf{x} \mid A\mathbf{x} = \mathbf{0} \}$,  
   - **Baza**: rozwiÄ…zania bazowe ukÅ‚adu jednorodnego,  
   - **Wymiar**: $n - \text{rk}(A)$ (twierdzenie o rzÄ™dzie).

---

#### **7. ğŸ’¡ Przedstaw podstawowe wÅ‚asnoÅ›ci i zastosowania iloczynu skalarnego wektorÃ³w.**  
**Definicja** (w $\mathbb{R}^n$):  
$$
\mathbf{u} \cdot \mathbf{v} = \sum_{i=1}^n u_i v_i = \|\mathbf{u}\| \|\mathbf{v}\| \cos \theta,
$$  
gdzie $\theta$ â€“ kÄ…t miÄ™dzy wektorami.  

**WÅ‚asnoÅ›ci**:  
- PrzemiennoÅ›Ä‡: $\mathbf{u} \cdot \mathbf{v} = \mathbf{v} \cdot \mathbf{u}$,  
- RozdzielnoÅ›Ä‡: $\mathbf{u} \cdot (\mathbf{v} + \mathbf{w}) = \mathbf{u} \cdot \mathbf{v} + \mathbf{u} \cdot \mathbf{w}$,  
- HomogenicznoÅ›Ä‡: $(c\mathbf{u}) \cdot \mathbf{v} = c (\mathbf{u} \cdot \mathbf{v})$.  

**Zastosowania**:  
- **OrtogonalnoÅ›Ä‡**: $\mathbf{u} \cdot \mathbf{v} = 0 \iff \mathbf{u} \perp \mathbf{v}$,  
- **Rzut wektora**: $\text{proj}_{\mathbf{v}} \mathbf{u} = \left( \frac{\mathbf{u} \cdot \mathbf{v}}{\|\mathbf{v}\|^2} \right) \mathbf{v}$,  
- **Norma (dÅ‚ugoÅ›Ä‡)**: $\|\mathbf{u}\| = \sqrt{\mathbf{u} \cdot \mathbf{u}}$,  
- **NierÃ³wnoÅ›Ä‡ Cauchyâ€™ego-Schwarza**: $|\mathbf{u} \cdot \mathbf{v}| \leq \|\mathbf{u}\| \|\mathbf{v}\|$.

---


## **Rachunek prawdopodobieÅ„stwa**

#### **1. ğŸ’¡ Podaj definicje miary probabilistycznej i omÃ³w jej wÅ‚asnoÅ›ci.**  
**Definicja**:  
MiarÄ… probabilistycznÄ… na przestrzeni mierzalnej $(\Omega, \mathcal{F})$ nazywamy funkcjÄ™ $P: \mathcal{F} \to [0,1]$ speÅ‚niajÄ…cÄ…:  
1. **NieujemnoÅ›Ä‡**: $P(A) \geq 0$ dla kaÅ¼dego $A \in \mathcal{F}$  
2. **Normalizacja**: $P(\Omega) = 1$  
3. **Przeliczalna addytywnoÅ›Ä‡**: Dla dowolnego ciÄ…gu zbiorÃ³w rozÅ‚Ä…cznych $A_1, A_2, \dots \in \mathcal{F}$:  
   $$
   P\left( \bigcup_{i=1}^{\infty} A_i \right) = \sum_{i=1}^{\infty} P(A_i)
   $$

**WÅ‚asnoÅ›ci**:  
- $P(\emptyset) = 0$  
- **MonotonicznoÅ›Ä‡**: JeÅ›li $A \subseteq B$, to $P(A) \leq P(B)$  
- **PodaddytywnoÅ›Ä‡**: $P\left( \bigcup_{i=1}^n A_i \right) \leq \sum_{i=1}^n P(A_i)$  
- **Zasada wÅ‚Ä…czeÅ„ i wyÅ‚Ä…czeÅ„**:  
  $$
  P\left( \bigcup_{i=1}^n A_i \right) = \sum_{i} P(A_i) - \sum_{i<j} P(A_i \cap A_j) + \cdots + (-1)^{n+1} P(A_1 \cap \cdots \cap A_n)
  $$  
- **CiÄ…gÅ‚oÅ›Ä‡ z doÅ‚u**: JeÅ›li $A_1 \subseteq A_2 \subseteq \cdots$, to $P\left( \bigcup_{i=1}^{\infty} A_i \right) = \lim_{n \to \infty} P(A_n)$  
- **CiÄ…gÅ‚oÅ›Ä‡ z gÃ³ry**: JeÅ›li $A_1 \supseteq A_2 \supseteq \cdots$, to $P\left( \bigcap_{i=1}^{\infty} A_i \right) = \lim_{n \to \infty} P(A_n)$.

---

#### **2. ğŸ“˜ Podaj wzÃ³r Bayesa.**  
**WzÃ³r Bayesa**: Dla zdarzeÅ„ $A, B$ o $P(B) > 0$:  
$$
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
$$  
**Rozszerzenie dla ukÅ‚adu zupeÅ‚nego zdarzeÅ„**:  
JeÅ›li $H_1, \dots, H_n$ sÄ… rozÅ‚Ä…czne, $\bigcup_{i=1}^n H_i = \Omega$, i $P(H_i) > 0$, to:  
$$
P(H_k|A) = \frac{P(A|H_k) P(H_k)}{\sum_{i=1}^n P(A|H_i) P(H_i)}
$$

---

#### **3. ğŸ“˜ Podaj definicjÄ™ wartoÅ›ci oczekiwanej zmiennej losowej i wymieÅ„ jej wÅ‚asnoÅ›ci.**  
**Definicja**:  
- **Dyskretna zmienna losowa** (przyjmujÄ…ca wartoÅ›ci $x_i$ z prawd. $p_i$):  
  $$
  E(X) = \sum_{i} x_i \cdot p_i
  $$  
- **CiÄ…gÅ‚a zmienna losowa** (z gÄ™stoÅ›ciÄ… $f(x)$):  
  $$
  E(X) = \int_{-\infty}^{\infty} x \cdot f(x)  dx
  $$  

**WÅ‚asnoÅ›ci**:  
- **LiniowoÅ›Ä‡**: $E(aX + bY) = aE(X) + bE(Y)$  
- **MonotonicznoÅ›Ä‡**: JeÅ›li $X \leq Y$ p.n., to $E(X) \leq E(Y)$  
- **Twierdzenie o caÅ‚kowaniu**: $E(g(X)) = \sum_i g(x_i) p_i$ (dyskretna) lub $E(g(X)) = \int_{-\infty}^{\infty} g(x) f(x)  dx$ (ciÄ…gÅ‚a)  
- **NiezaleÅ¼noÅ›Ä‡**: JeÅ›li $X,Y$ niezaleÅ¼ne, to $E(XY) = E(X)E(Y)$  
- **StaÅ‚a**: $E(c) = c$ dla $c \in \mathbb{R}$.

---

#### **4. ğŸ“˜ Podaj definicjÄ™ dystrybuanty zmiennej losowej i omÃ³w jej wÅ‚asnoÅ›ci.**  
**Definicja**:  
DystrybuantÄ… zmiennej losowej $X$ nazywamy funkcjÄ™ $F_X: \mathbb{R} \to [0,1]$:  
$$
F_X(x) = P(X \leq x)
$$  

**WÅ‚asnoÅ›ci**:  
1. **NiemalejÄ…ca**: $x_1 < x_2 \implies F_X(x_1) \leq F_X(x_2)$  
2. **Prawostronnie ciÄ…gÅ‚a**: $\lim_{y \to x^+} F_X(y) = F_X(x)$  
3. **Granice**:  
   $$
   \lim_{x \to -\infty} F_X(x) = 0, \quad \lim_{x \to \infty} F_X(x) = 1
   $$  
4. **Obliczanie prawdopodobieÅ„stw**:  
   $$
   P(a < X \leq b) = F_X(b) - F_X(a)
   $$  
5. **ZwiÄ…zek z gÄ™stoÅ›ciÄ…** (dla ciÄ…gÅ‚ych):  
   $$
   f_X(x) = \frac{d}{dx} F_X(x) \quad \text{(tam gdzie istnieje)}
   $$

---

#### **5. ğŸ“˜ Podaj definicjÄ™ funkcji prawdopodobieÅ„stwa (dyskretna) i gÄ™stoÅ›ci (ciÄ…gÅ‚a) zmiennej losowej oraz omÃ³w ich wÅ‚asnoÅ›ci.**  
**Funkcja prawdopodobieÅ„stwa** (dla dyskretnej zmiennej losowej):  
Funkcja $p: \mathbb{R} \to [0,1]$ taka, Å¼e:  
$$
p(x_i) = P(X = x_i) \quad \text{oraz} \quad \sum_{i} p(x_i) = 1
$$  
**WÅ‚asnoÅ›ci**:  
- $p(x) = 0$ dla $x \notin \{x_i\}$  
- $P(X \in A) = \sum_{x_i \in A} p(x_i)$.

**Funkcja gÄ™stoÅ›ci** (dla ciÄ…gÅ‚ej zmiennej losowej):  
Funkcja $f: \mathbb{R} \to [0,\infty)$ taka, Å¼e:  
$$
P(a \leq X \leq b) = \int_a^b f(x)  dx \quad \text{oraz} \quad \int_{-\infty}^{\infty} f(x)  dx = 1
$$  
**WÅ‚asnoÅ›ci**:  
- $f(x) \geq 0$  
- $P(X = a) = 0$ dla kaÅ¼dego $a \in \mathbb{R}$  
- $F_X(x) = \int_{-\infty}^x f(t)  dt$.

---

#### **6. ğŸ“˜ Podaj przykÅ‚ady rozkÅ‚adÃ³w dyskretnych i ciÄ…gÅ‚ych zmiennych losowych.**  
**RozkÅ‚ady dyskretne**:  
1. **Bernoulliego** ($X \sim \text{Ber}(p)$):  
   - $P(X=1) = p$, $P(X=0) = 1-p$  
   - PrzykÅ‚ad: wynik pojedynczego rzutu monetÄ…  
2. **Dwumianowy** ($X \sim \text{Bin}(n,p)$):  
   - $P(X=k) = \binom{n}{k} p^k (1-p)^{n-k}$  
   - PrzykÅ‚ad: liczba sukcesÃ³w w $n$ prÃ³bach Bernoulliego  
3. **Poissona** ($X \sim \text{Pois}(\lambda)$):  
   - $P(X=k) = e^{-\lambda} \frac{\lambda^k}{k!}$  
   - PrzykÅ‚ad: liczba klientÃ³w w sklepie w ciÄ…gu godziny  
4. **Geometryczny** ($X \sim \text{Geom}(p)$):  
   - $P(X=k) = (1-p)^{k-1} p$  
   - PrzykÅ‚ad: liczba prÃ³b do pierwszego sukcesu  

**RozkÅ‚ady ciÄ…gÅ‚e**:  
1. **Jednostajny** ($X \sim \mathcal{U}(a,b)$):  
   - $f(x) = \frac{1}{b-a}$ dla $x \in [a,b]$  
   - PrzykÅ‚ad: losowy punkt na odcinku $[a,b]$  
2. **Normalny** ($X \sim \mathcal{N}(\mu,\sigma^2)$):  
   - $f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$  
   - PrzykÅ‚ad: wzrost w populacji  
3. **WykÅ‚adniczy** ($X \sim \text{Exp}(\lambda)$):  
   - $f(x) = \lambda e^{-\lambda x}$ dla $x \geq 0$  
   - PrzykÅ‚ad: czas oczekiwania na zdarzenie  
4. **Gamma** ($X \sim \Gamma(\alpha,\beta)$):  
   - $f(x) = \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-1} e^{-\beta x}$  
   - PrzykÅ‚ad: czas oczekiwania na $k$ zdarzeÅ„ Poissona.

---

#### **7. ğŸ“˜ Podaj definicjÄ™ wariancji i odchylenia standardowego zmiennej losowej oraz wymieÅ„ ich wÅ‚asnoÅ›ci.**  
**Definicja wariancji**:  
$$
\text{Var}(X) = E\left[(X - E[X])^2\right] = E[X^2] - (E[X])^2
$$  
**WÅ‚asnoÅ›ci wariancji**:  
- $\text{Var}(c) = 0$ dla staÅ‚ej $c$  
- $\text{Var}(aX + b) = a^2 \text{Var}(X)$  
- JeÅ›li $X,Y$ niezaleÅ¼ne, to $\text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y)$  
- $\text{Var}(X) \geq 0$  

**Definicja odchylenia standardowego**:  
$$
\sigma_X = \sqrt{\text{Var}(X)}
$$  
**WÅ‚asnoÅ›ci odchylenia standardowego**:  
- $\sigma_{aX + b} = |a| \sigma_X$  
- Interpretacja: miara dyspersji wokÃ³Å‚ wartoÅ›ci oczekiwanej.

---

### Kluczowe koncepcje  
- **Miary probabilistyczne**: Fundament teorii prawdopodobieÅ„stwa (aksjomatyka KoÅ‚mogorowa).  
- **WzÃ³r Bayesa**: Podstawa wnioskowania bayesowskiego.  
- **WartoÅ›Ä‡ oczekiwana**: "Åšrodek ciÄ™Å¼koÅ›ci" rozkÅ‚adu.  
- **Dystrybuanta**: Uniwersalny opis rozkÅ‚adu (dziaÅ‚a dla wszystkich typÃ³w zmiennych).  
- **Wariancja**: Kluczowa miara ryzyka w finansach i statystyce.  

---

## **Statystyka Matematyczna**

#### **1. ğŸ’¡ OmÃ³w miary poÅ‚oÅ¼enia i zmiennoÅ›ci danych.**  
**Miary poÅ‚oÅ¼enia**:  
- **Åšrednia arytmetyczna**:  
  $$
  \bar{x} = \frac{1}{n} \sum_{i=1}^n x_i
  $$  
  *Zalety*: WraÅ¼liwa na wszystkie dane. *Wady*: WraÅ¼liwa na wartoÅ›ci skrajne.  
- **Mediana**: WartoÅ›Ä‡ Å›rodkowa w uporzÄ…dkowanym zbiorze danych.  
  *Zastosowanie*: Odporne na outliers (np. przy danych o rozkÅ‚adzie skoÅ›nym).  
- **Dominanta (moda)**: NajczÄ™Å›ciej wystÄ™pujÄ…ca wartoÅ›Ä‡.  

**Miary zmiennoÅ›ci**:  
- **Wariancja**:  
  $$
  s^2 = \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2
  $$  
- **Odchylenie standardowe**: $ s = \sqrt{s^2} $ â€“ interpretowalne w jednostkach danych.  
- **RozstÄ™p**: $ R = x_{\text{max}} - x_{\text{min}} $.  
- **IQR (miÄ™dzykwartylowy)**: $ Q_3 - Q_1 $ â€“ odpornoÅ›Ä‡ na outliers.  

**PrzykÅ‚ad**:  
Dla danych $[2, 4, 4, 6, 8]$:  
- Åšrednia: $4.8$, Mediana: $4$, Moda: $4$, Wariancja: $4.8$, Odchylenie: $2.19$, IQR: $4$.

---

#### **2. ğŸ’¡ OmÃ³w graficznÄ… prezentacjÄ™ danych.**  
**Wykresy dla danych jakoÅ›ciowych**:  
- **Wykres koÅ‚owy**: Proporcje kategorii (np. udziaÅ‚ procentowy preferencji).  
- **Wykres sÅ‚upkowy**: PorÃ³wnanie czÄ™stoÅ›ci kategorii.  

**Wykresy dla danych iloÅ›ciowych**:  
- **Histogram**: RozkÅ‚ad czÄ™stoÅ›ci przedziaÅ‚Ã³w wartoÅ›ci (np. przedziaÅ‚y wzrostu).  
- **Boxplot (wykres pudeÅ‚kowy)**:  
  - Linia Å›rodkowa: Mediana ($Q_2$).  
  - "PudeÅ‚ko": $Q_1$ do $Q_3$.  
  - "WÄ…sy": Zakres danych (z wyÅ‚Ä…czeniem outliers).  
  - **Outliers**: Punkty poza $1.5 \times \text{IQR}$.  
- **Wykres rozrzutu (scatter plot)**: ZaleÅ¼noÅ›Ä‡ miÄ™dzy dwiema zmiennymi (np. wzrost vs. waga).  

**PrzykÅ‚ad**:  
Boxplot dla danych $[10, 12, 12, 13, 14, 15, 16, 20]$:  
- $Q_1 = 12$, $Q_2 = 13.5$, $Q_3 = 15.5$, IQR = $3.5$, Outlier: $20$.

---

#### **3. ğŸ’¡ OmÃ³w weryfikacjÄ™ hipotez dotyczÄ…cych frakcji.**  
**Kroki testowania hipotezy o frakcji $p$**:  
1. **FormuÅ‚owanie hipotez**:  
   - $H_0: p = p_0$ (np. $p_0 = 0.5$ â€“ "50% wyborcÃ³w preferuje kandydata").  
   - $H_1: p \neq p_0$ (dwustronna) lub $H_1: p > p_0$ (jednostronna).  
2. **Statystyka testowa** (dla duÅ¼ych prÃ³b, $np_0 \geq 5$ i $n(1-p_0) \geq 5$):  
   $$
   Z = \frac{\hat{p} - p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}}, \quad \hat{p} = \frac{\text{liczba sukcesÃ³w}}{n}
   $$  
3. **Decyzja**:  
   - PorÃ³wnaj $|Z|$ z wartoÅ›ciÄ… krytycznÄ… $z_{\alpha/2}$ (np. $1.96$ dla $\alpha = 0.05$).  
   - JeÅ›li $|Z| > z_{\alpha/2}$, odrzucamy $H_0$.  

**PrzykÅ‚ad**:  
Dla $n=100$, $\hat{p}=0.6$, $p_0=0.5$:  
$$
Z = \frac{0.6 - 0.5}{\sqrt{\frac{0.5 \times 0.5}{100}}} = 2.0 \quad (\text{Odrzucamy } H_0 \text{ dla } \alpha=0.05).
$$

---

#### **4. ğŸ’¡ OmÃ³w weryfikacjÄ™ hipotez dotyczÄ…cych Å›redniej.**  
**Test dla Å›redniej ($\mu$) w rozkÅ‚adzie normalnym**:  
1. **Hipotezy**:  
   - $H_0: \mu = \mu_0$, $H_1: \mu \neq \mu_0$.  
2. **Statystyka testowa**:  
   - **Znane $\sigma$**:  
     $$
     Z = \frac{\bar{X} - \mu_0}{\sigma/\sqrt{n}}
     $$  
   - **Nieznane $\sigma$**:  
     $$
     t = \frac{\bar{X} - \mu_0}{s/\sqrt{n}} \quad (\text{rozkÅ‚ad } t\text{-Studenta z } n-1 \text{ stopniami swobody}).
     $$  
3. **Decyzja**:  
   - PorÃ³wnaj statystykÄ™ z wartoÅ›ciÄ… krytycznÄ… ($z_{\alpha/2}$ lub $t_{\alpha/2, n-1}$).  

**PrzykÅ‚ad**:  
Dane: $\bar{x}=105$, $\mu_0=100$, $s=10$, $n=25$:  
$$
t = \frac{105 - 100}{10/\sqrt{25}} = 2.5 \quad (\text{Odrzucamy } H_0 \text{ dla } t_{0.025,24} \approx 2.064).
$$

---

#### **5. ğŸ’¡ OmÃ³w weryfikacjÄ™ hipotez dotyczÄ…cych odchylenia standardowego.**  
**Test dla wariancji ($\sigma^2$) w rozkÅ‚adzie normalnym**:  
1. **Hipotezy**:  
   - $H_0: \sigma^2 = \sigma_0^2$, $H_1: \sigma^2 \neq \sigma_0^2$.  
2. **Statystyka testowa**:  
   $$
   \chi^2 = \frac{(n-1)s^2}{\sigma_0^2} \quad (\text{rozkÅ‚ad chi-kwadrat z } n-1 \text{ stopniami swobody}).
   $$  
3. **Decyzja**:  
   - PorÃ³wnaj $\chi^2$ z wartoÅ›ciami krytycznymi $\chi^2_{\alpha/2, n-1}$ i $\chi^2_{1-\alpha/2, n-1}$.  

**PrzykÅ‚ad**:  
Dla $n=30$, $s^2=4$, $\sigma_0^2=3$:  
$$
\chi^2 = \frac{29 \times 4}{3} \approx 38.67 \quad (\text{Odrzucamy } H_0 \text{ jeÅ›li } \chi^2 > 45.72 \text{ lub } \chi^2 < 16.05 \text{ dla } \alpha=0.05).
$$

---

#### **6. ğŸ’¡ OmÃ³w weryfikacjÄ™ hipotez dotyczÄ…cych niezaleÅ¼noÅ›ci dwÃ³ch zmiennych.**  
**Test chi-kwadrat niezaleÅ¼noÅ›ci**:  
1. **Hipotezy**:  
   - $H_0$: Zmienne sÄ… niezaleÅ¼ne, $H_1$: Zmienne sÄ… zaleÅ¼ne.  
2. **Statystyka testowa**:  
   $$
   \chi^2 = \sum \frac{(O_{ij} - E_{ij})^2}{E_{ij}}, \quad E_{ij} = \frac{(\text{suma wiersza } i) \times (\text{suma kolumny } j)}{n}
   $$  
   gdzie $O_{ij}$ â€“ obserwowane czÄ™stoÅ›ci, $E_{ij}$ â€“ czÄ™stoÅ›ci oczekiwane przy niezaleÅ¼noÅ›ci.  
3. **Decyzja**:  
   - PorÃ³wnaj $\chi^2$ z wartoÅ›ciÄ… krytycznÄ… $\chi^2_{\alpha, (r-1)(c-1)}$ ($r$ â€“ liczba wierszy, $c$ â€“ kolumn).  

**PrzykÅ‚ad**:  
Tabela $2 \times 2$ dla pÅ‚ci a preferencji produktu:  
$$
\chi^2 = \frac{(50-40)^2}{40} + \frac{(30-40)^2}{40} + \cdots \quad (\text{Odrzucamy } H_0 \text{ jeÅ›li } \chi^2 > 3.84).
$$

---

### Kluczowe wnioski  
- **Miary statystyczne**: Åšrednia i mediana uzupeÅ‚niajÄ… siÄ™ w opisie danych.  
- **Wizualizacja**: Boxplot pokazuje rozkÅ‚ad i outliers efektywniej niÅ¼ histogram.  
- **Testowanie hipotez**:  
  - Dla frakcji uÅ¼ywamy testu $Z$, dla Å›redniej â€“ $Z$ lub $t$, dla wariancji â€“ $\chi^2$.  
  - Test chi-kwadrat jest uniwersalny dla tabel kontyngencji.  

---


## **Analiza Danych i Metody Numeryczne**

#### **1. ğŸ’¡ OmÃ³w zagadnienie interpolacji wielomianowej. Podaj algorytm Lagrange'a lub Newtona.**  
**Interpolacja wielomianowa**:  
Cel: Znalezienie wielomianu $P_n(x)$ stopnia $\leq n$, ktÃ³ry przechodzi przez $n+1$ punktÃ³w $(x_i, y_i)$ (tzn. $P_n(x_i) = y_i$).  

**Algorytm Lagrange'a**:  
1. **Wielomian bazowy**:  
   $$
   \ell_i(x) = \prod_{\substack{j=0 \\ j \neq i}}^{n} \frac{x - x_j}{x_i - x_j}
   $$  
2. **Wielomian interpolacyjny**:  
   $$
   P_n(x) = \sum_{i=0}^{n} y_i \cdot \ell_i(x)
   $$  
   *PrzykÅ‚ad*: Dla punktÃ³w $(-1,1), (0,0), (1,1)$:  
   $$
   P_2(x) = 1 \cdot \frac{x(x-1)}{2} + 0 \cdot \frac{(x+1)(x-1)}{-1} + 1 \cdot \frac{(x+1)x}{2} = x^2
   $$  

**Algorytm Newtona**:  
1. **Ilorazy rÃ³Å¼nicowe**:  
   - $f[x_i] = y_i$  
   - $f[x_i,x_j] = \frac{f[x_j]-f[x_i]}{x_j-x_i}$  
   - $f[x_i,x_j,x_k] = \frac{f[x_j,x_k]-f[x_i,x_j]}{x_k-x_i}$  
2. **Wielomian**:  
   $$
   P_n(x) = f[x_0] + f[x_0,x_1](x-x_0) + f[x_0,x_1,x_2](x-x_0)(x-x_1) + \cdots
   $$  
   *Zaleta*: Dodanie nowego punktu wymaga tylko jednego dodatkowego skÅ‚adnika.  

---

#### **2. ğŸ’¡ OmÃ³w numeryczne rozwiÄ…zywanie rÃ³wnaÅ„ nieliniowych, w szczegÃ³lnoÅ›ci metodÄ™ iteracji prostych lub metodÄ™ Newtona.**  
**Metoda iteracji prostych**:  
1. PrzeksztaÅ‚Ä‡ $f(x)=0$ do postaci $x = g(x)$.  
2. Iteruj: $x_{k+1} = g(x_k)$.  
   *Warunek zbieÅ¼noÅ›ci*: $|g'(x)| < 1$ w otoczeniu pierwiastka.  
   *PrzykÅ‚ad*: Dla $x = e^{-x}$:  
   $$
   x_{k+1} = e^{-x_k}, \quad x_0 = 0.5 \to x_1 \approx 0.6065 \to x_2 \approx 0.5452 \to \cdots
   $$  

**Metoda Newtona (stycznych)**:  
1. Iteracja:  
   $$
   x_{k+1} = x_k - \frac{f(x_k)}{f'(x_k)}
   $$  
2. *ZbieÅ¼noÅ›Ä‡*: Kwadratowa, gdy $f'(x^*) \neq 0$.  
   *PrzykÅ‚ad*: Dla $f(x) = x^2 - 2$:  
   $$
   x_{k+1} = x_k - \frac{x_k^2 - 2}{2x_k} = \frac{x_k}{2} + \frac{1}{x_k}, \quad x_0 = 1 \to x_1 = 1.5 \to x_2 \approx 1.4167
   $$  

---

#### **3. ğŸ’¡ OmÃ³w numeryczne rozwiÄ…zywanie ukÅ‚adÃ³w rÃ³wnaÅ„ liniowych, w szczegÃ³lnoÅ›ci metodÄ™ Jacobiego lub metodÄ™ Gaussa-Seidla.**  
**Metoda Jacobiego**:  
1. RozkÅ‚ad macierzy: $A = D + R$ ($D$ â€“ diagonalna, $R$ â€“ reszta).  
2. Iteracja:  
   $$
   \mathbf{x}^{(k+1)} = D^{-1} \left( \mathbf{b} - R \mathbf{x}^{(k)} \right)
   $$  
   *WspÃ³Å‚rzÄ™dnie*:  
   $$
   x_i^{(k+1)} = \frac{1}{a_{ii}} \left( b_i - \sum_{j \neq i} a_{ij} x_j^{(k)} \right)
   $$  

**Metoda Gaussa-Seidla**:  
Wykorzystuje najnowsze przybliÅ¼enia:  
$$
x_i^{(k+1)} = \frac{1}{a_{ii}} \left( b_i - \sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \sum_{j=i+1}^{n} a_{ij} x_j^{(k)} \right)
$$  
*PrzykÅ‚ad*: Dla ukÅ‚adu:  
$$
\begin{cases}
4x_1 - x_2 = 3 \\
-2x_1 + 5x_2 = 2
\end{cases}
$$  
- **Jacobi**: $x_1^{(1)} = \frac{3 + x_2^{(0)}}{4}, \quad x_2^{(1)} = \frac{2 + 2x_1^{(0)}}{5}$  
- **Gauss-Seidel**: $x_1^{(1)} = \frac{3 + x_2^{(0)}}{4}, \quad x_2^{(1)} = \frac{2 + 2x_1^{(1)}}{5}$  

---

#### **4. ğŸ’¡ OmÃ³w metodÄ™ najmniejszych kwadratÃ³w, w szczegÃ³lnoÅ›ci metodÄ™ regresji liniowej.**  
**Cel**: Minimalizacja sumy kwadratÃ³w odchyleÅ„ (residuÃ³w) miÄ™dzy danymi a modelem.  

**Regresja liniowa** ($y = ax + b$):  
1. Funkcja bÅ‚Ä™du:  
   $$
   S(a,b) = \sum_{i=1}^{n} (y_i - (a x_i + b))^2
   $$  
2. RÃ³wnania normalne:  
   $$
   \begin{cases}
   a \sum x_i^2 + b \sum x_i = \sum x_i y_i \\
   a \sum x_i + b \cdot n = \sum y_i
   \end{cases}
   $$  
3. RozwiÄ…zanie:  
   $$
   a = \frac{n \sum x_i y_i - \sum x_i \sum y_i}{n \sum x_i^2 - (\sum x_i)^2}, \quad b = \bar{y} - a \bar{x}
   $$  

**PrzykÅ‚ad**:  
Dane: $(1,1), (2,2), (3,2)$:  
- $\sum x_i = 6$, $\sum y_i = 5$, $\sum x_i y_i = 1\cdot1 + 2\cdot2 + 3\cdot2 = 11$, $\sum x_i^2 = 14$  
- $a = \frac{3 \cdot 11 - 6 \cdot 5}{3 \cdot 14 - 36} = \frac{3}{6} = 0.5$, $b = \frac{5}{3} - 0.5 \cdot 2 \approx 0.833$  
- Model: $y = 0.5x + 0.833$  

---

### Kluczowe wnioski  
- **Interpolacja**:  
  - Lagrange: Prosty koncepcyjnie, ale kosztowny obliczeniowo ($O(n^2)$).  
  - Newton: Elastyczny przy dodawaniu punktÃ³w.  
- **RÃ³wnania nieliniowe**:  
  - Iteracja prosta: Åatwa implementacja, ale wolna zbieÅ¼noÅ›Ä‡.  
  - Newton: Szybki, ale wymaga pochodnej.  
- **UkÅ‚ady liniowe**:  
  - Jacobi: RÃ³wnolegÅ‚y, ale wolniejszy.  
  - Gauss-Seidel: Szybszy, ale sekwencyjny.  
- **MNK**:  
  - Podstawowe narzÄ™dzie w data science (np. trend liniowy w danych).  

---
